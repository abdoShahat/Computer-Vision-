{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Chapter we will know :-\n",
    "• How to use Haar cascades\n",
    "\n",
    "• What are integral images\n",
    "\n",
    "• What is adaptive boosting\n",
    "\n",
    "• How to detect and track faces in a live video stream\n",
    "\n",
    "• How to detect and track eyes in a live video stream\n",
    "\n",
    "• How to automatically overlay sunglasses on top of a person's face\n",
    "\n",
    "• How to detect ears, nose, and mouth\n",
    "\n",
    "• How to detect pupils using shape analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Haar cascades to detect things"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "When we say Haar cascades, we are actually talking about cascade classifiers based on Haar features. To understand what this means, we need to take a step back and understand why we need this in the first place. Back in 2001, Paul Viola and Michael Jones came up with a very effective object detection method in their seminal paper. It has become one of the major landmarks in the field of machine learning. \n",
    "In their paper, they have described a machine learning technique where a boosted cascade of simple classifiers is used to get an overall classifier that performs really well. This way, we can circumvent the process of building a single complex classifier that performs with high accuracy. The reason this is so amazing is because building a robust single-step classifier is a computationally intensive process. Besides, we need a lot of training data to build such a classifier. The model ends up becoming complex and the performance might not be up to the mark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to detect an object like, say, a pineapple. To solve this, we need to build a machine learning system that will learn what a pineapple looks like. It should be able to tell us if an unknown image contains a pineapple or not. To achieve something like this, we need to train our system. In the realm of machine learning, we have a lot of methods available to train a system. It's a lot like training a dog, except that it won't fetch the ball for you! To train our system, we take a lot of pineapple and non-pineapple images, and then feed them into the system. Here, pineapple images are called positive images and the non-pineapple images are called negative images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coming to the topic of face detection,\n",
    "let's see how to train a system to detect faces. If we want to build a machine learning system, we first need to extract features from all the images. In our case, the machine learning algorithms will use these features to learn what a face looks like. We use Haar features to build our feature vectors. Haar features are simple summations and differences of patches across the image. We do this at multiple image sizes to make sure our system is scale invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are integral images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to compute Haar features, we will have to compute the summations of many different rectangular regions within the image. If we want to effectively build the feature set, we need to compute these summations at multiple scales. This is a very expensive process! If we want to build a real time system, we cannot spend so many cycles in computing these sums. So we use something called integral images"
   ]
  },
  {
   "attachments": {
    "1.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1.PNG](attachment:1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting and tracking faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "from os import path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the xml file of haarcascade\n",
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "scaling_factor = 1.5\n",
    "\n",
    "#reading from live cam \n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx=scaling_factor,fy=scaling_factor,interpolation = cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detectMultscale to detect all the faces in the image , 1.3>> time to check \n",
    "    face_rects = face_cascade.detectMultiScale(gray,1.3,5) \n",
    "    for(x,y,w,h) in face_rects:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    cv2.imshow('Face Detector',frame)\n",
    "    \n",
    "    c=cv2.waitKey(1)\n",
    "    if c==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the mask \n",
    "face_mask = cv2.imread('HNBL.webp')\n",
    "copy = cv2.cvtColor(face_mask,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_mask , w_mask=face_mask.shape[:2]\n",
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "scaling_factor = 1.5\n",
    "\n",
    "while True :\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx=scaling_factor,fy=scaling_factor,interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    face_rects = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for(x,y,w,h) in face_rects:\n",
    "        if h > 0 and w > 0:\n",
    "            h,w = int(1.4*h),int(1.0*w)\n",
    "            y -=0.1*h\n",
    "            y = int(y)\n",
    "            # Extract the region of interest from the image\n",
    "            frame_roi = frame[y:y+h , x:x+w]\n",
    "            face_mask_small = cv2.resize(face_mask,(w,h),interpolation=cv2.INTER_AREA)\n",
    "            \n",
    "            # Convert color image to grayscale and threshold it\n",
    "            gray_mask = cv2.cvtColor(face_mask_small,cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            ret,mask = cv2.threshold(gray_mask,180,255,cv2.THRESH_BINARY_INV)\n",
    "            \n",
    "            # Create an inverse mask\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            \n",
    "            # Use the mask to extract the face mask region of interest\n",
    "            masked_face = cv2.bitwise_and(face_mask_small,face_mask_small , mask=mask)\n",
    "            \n",
    "            # Use the inverse mask to get the remaining part of the image\n",
    "            masked_frame = cv2.bitwise_and(frame_roi, frame_roi, mask=mask_inv)\n",
    "            \n",
    "            # add the two images to get the final output\n",
    "            frame[y:y+h, x:x+w] = cv2.add(masked_face, masked_frame)\n",
    "            \n",
    "    cv2.imshow('Face Detector', frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how to build an eye detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important package\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "from os import path \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_eye.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "scalling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    frame = cv2.resize(frame,None,fx=scalling_factor,fy=scalling_factor,interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray  = gray[y:y+h , x:x+w] # face in gray level \n",
    "        roi_frame = frame[y:y+h , x:x+w] # face in RGB level \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for(xe,ye,we,he) in eyes:\n",
    "            center = (int(xe + 0.5*we ),int(ye+0.5*he))\n",
    "            radius = int(0.3*(we+he))\n",
    "            color = (0,255,0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_frame,center,radius,color,thickness)\n",
    "        \n",
    "    cv2.imshow('eye detector',frame)\n",
    "    cv2.imshow('face gray',roi_gray)\n",
    "    cv2.imshow('face BGR',roi_frame)\n",
    "        \n",
    "    c=cv2.waitKey(1)\n",
    "    if c==27:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with eyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import important package\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "from os import path \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_frontalface_default.xml')\n",
    "face_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "xml_classifier = path.join(path.dirname(cv2.__file__),'data','haarcascade_eye.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(xml_classifier)\n",
    "\n",
    "img = cv2.imread('1.jpg')\n",
    "sunglass = cv2.imread('3.png')\n",
    "\n",
    "gray = cv2.cvtColor(img , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "centers = []\n",
    "faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
    "\n",
    "for(x,y,w,h) in faces:\n",
    "    roi_gray = gray[y:y+h , x:x+w]\n",
    "    roi_color = img[y:y+h , x:x+w]\n",
    "#     cv2.imshow('Sunglasses', roi_gray)    \n",
    "#     cv2.waitKey()    \n",
    "#     cv2.destroyAllWindows()\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray,1.3,5)\n",
    "    print('eyes is',eyes)\n",
    "    for(xe,ye,we,he) in eyes:\n",
    "        centers.append(( int(x)+int(xe+0.5*we), int(y)+int(ye+0.5*he)))\n",
    "\n",
    "print('here')\n",
    "    \n",
    "if len(centers) > 0 :\n",
    "    # Overlay sunglasses; the factor 2.12 is customizable depending on the size of the face\n",
    "    sunglasses_width = 2.12 * abs(centers[1][0] - centers[0][0])\n",
    "    overlay_img = np.ones(img.shape, np.uint8) * 255\n",
    "    \n",
    "#     cv2.imshow('overlay',overlay_img)\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroyWindow()\n",
    "    \n",
    "    h, w = sunglass.shape[:2]\n",
    "    scaling_factor = sunglasses_width / w\n",
    "    overlay_sunglasses = cv2.resize(sunglass, None, fx=scaling_factor,fy=scaling_factor,interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "#     cv2.imshow('overlay2',overlay_img)\n",
    "#     cv2.waitKey()\n",
    "#     cv2.destroy()\n",
    "    \n",
    "    x = centers[0][0] if centers[0][0] < centers[1][0] else centers[1][0]\n",
    "    \n",
    "    x -= int(0.26*overlay_sunglasses.shape[1])\n",
    "    y += int(0.85*overlay_sunglasses.shape[0])\n",
    "    \n",
    "    h, w = overlay_sunglasses.shape[:2]    \n",
    "    overlay_img[y:y+h, x:x+w] = overlay_sunglasses\n",
    "    \n",
    "    gray_sunglasses = cv2.cvtColor(overlay_img, cv2.COLOR_BGR2GRAY)    \n",
    "    ret, mask = cv2.threshold(gray_sunglasses, 110, 255, cv2.THRESH_BINARY)    \n",
    "    mask_inv = cv2.bitwise_not(mask)    \n",
    "    temp = cv2.bitwise_and(img, img, mask=mask)    \n",
    "    temp2 = cv2.bitwise_and(overlay_img, overlay_img, mask=mask_inv)    \n",
    "    final_img = cv2.add(temp, temp2)\n",
    "    \n",
    "    cv2.imshow('Eye Detector', img)    \n",
    "    cv2.imshow('Sunglasses', final_img)    \n",
    "    cv2.waitKey()    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
